{"version":3,"sources":["../../src/cli/translate.ts","../../src/ai/openai.ts","../../src/env/index.ts","../../src/ai/translate.ts"],"sourcesContent":["#!/usr/bin/env node\nimport { program } from 'commander';\nimport { translateMarkdownFile } from '../ai/translate';\nimport { readFileSync } from 'fs';\nimport path from 'path';\n\nprogram\n  .name('translate-md')\n  .description('CLI tool to translate markdown files using AI')\n  .version('1.0.0');\n\nprogram\n  .command('translate')\n  .description('Translate a markdown file to target language')\n  .requiredOption('-i, --input <path>', 'Input markdown file path')\n  .requiredOption('-o, --output <path>', 'Output file path')\n  .requiredOption('-l, --language <language>', 'Target language (e.g. \"Chinese\", \"French\")')\n  .action(async (options) => {\n    try {\n      console.log(`Translating ${options.input} to ${options.language}...`);\n      await translateMarkdownFile(\n        path.resolve(options.input),\n        path.resolve(options.output),\n        { targetLanguage: options.language }\n      );\n      console.log(`Translation saved to ${options.output}`);\n    } catch (error) {\n      console.error('Translation failed:', error);\n      process.exit(1);\n    }\n  });\n\nprogram.parseAsync(process.argv).catch(console.error);\n","import { Effect } from 'effect';\nimport { ClientOptions, OpenAI } from 'openai';\nimport { AiService, McpClientService } from 'src/service';\nimport { Env } from '../env';\n\nconst configuration: ClientOptions = {\n  apiKey: Env.default_apiKey,\n  baseURL: Env.default_apiBaseUrl,\n};\nexport const defaultOpenai = new OpenAI(configuration);\n\nexport type AI = {\n  openai: OpenAI;\n  model?: string;\n  max_tokens?: number;\n  temperature?: number;\n};\nconst defaultConfig = {\n  //   model: \"gpt-3.5-turbo\",\n  /** 智谱清言 免费模型 */\n  model: 'GLM-4-Flash',\n  //   max_tokens: undefined,\n  max_tokens: 9999,\n  temperature: 0.3,\n};\nexport async function ai搜索关键词提取(ai: AI = { openai: defaultOpenai }, userInput: string) {\n  // 你是一个专业辅助用户搜索的助手，请从用户的提问之中拆分和联想出可以用于搜索的词组\n\n  // ## 你回答的内容\n  // 1. 格式：你的回答应该是一个单行json字符串数组，不要包含其他的内容\n  // 2. 不仅仅要包含用户提问中出现过的关键词，你还应该要联想到关键词的可能变体\n\n  // ## 搜索引擎的特性\n  // 1. 搜索程序支持使用空格连接多个关键词\n  // 2. 有时候单个关键词可以搜索到相关内容，多个关键词连接反而搜索不到，所以你不仅要返回空格连接的多个关键词，还应该返回需要搜索的单个关键词之类的，但是太多的单个关键词又可能搜索到无关紧要的内容，这个就是需要你取舍的地方了\n  const completion: OpenAI.Chat.Completions.ChatCompletion =\n    await ai.openai.chat.completions.create({\n      model: ai.model ?? defaultConfig.model,\n      messages: [\n        {\n          role: 'system',\n          content: `你是一名助理，专门协助用户进行搜索。请按照以下规则提供答案：\n\n1. 输出格式：**JSON 格式**，不要使用代码块,要确保你的回答可以直接被 JSON.parse。\n2. 内容要求：\n   - 答案应该是**单行的 JSON 字符串数组**。\n   - 包含**用户问题中的关键词**及其**可能的变体**。\n3. 搜索引擎功能：\n   - 支持使用空格连接多个关键词，但也要考虑**单个关键词**的可能性。\n   - 选择合适的关键词，以避免返回过多无关的结果。\n\n示例：\n用户: “有哪些关键词”\n你: [\"关键词1\", \"关键词2\"]\n`,\n        },\n        { role: 'user', content: userInput },\n      ],\n      stream: false,\n      max_tokens: ai.max_tokens ?? defaultConfig.max_tokens,\n      temperature: ai.temperature ?? defaultConfig.temperature,\n    });\n  const resStr = completion.choices[0].message!.content!;\n  let queryArr;\n  try {\n    if (resStr.startsWith('```')) {\n      const lines = resStr.split('\\n');\n      lines[0] = '';\n      lines[lines.length - 1] = '';\n      queryArr = JSON.parse(lines.join('\\n'));\n    } else {\n      queryArr = JSON.parse(resStr);\n    }\n  } catch (error) {\n    console.log('[error]', error);\n    queryArr = [resStr];\n  }\n  return {\n    res: queryArr,\n    raw: resStr,\n  };\n}\nexport async function ai回答(\n  ai: AI = { openai: defaultOpenai },\n  userInput: string,\n  searchMd: string,\n) {\n  const completion: OpenAI.Chat.Completions.ChatCompletion =\n    await ai.openai.chat.completions.create({\n      model: ai.model ?? defaultConfig.model,\n      messages: [\n        {\n          role: 'system',\n          content: `你是用户的笔记ai提问助手，请根据用户的问题和你检索到的笔记内容来回答用户的问题\n## 回答的格式\n\n你的回答要表示是基于哪些块的内容回答的，表现方式是在对应回答的后面添加 :[种花心得(这个块的内容摘要)](siyuan://blocks/20240113141417-va4uedb(笔记块的id))\n例如 :\n\n提问:怎么养兰花\n回答:\n\n1. 保持适宜的空气湿度 [养兰花的第三天](siyuan://blocks/20130123242415-ad32fad12)\n2. 需要准备的一些工具:.....  [种花心得](siyuan://blocks/20160133242325-d23dfg1)\n\n## 注意你的回答最后面附加的链接 [] 内填的是这个块的摘要文本 () 中的 siyuan://blocks/id 是思源特有的链接方式\n`,\n        },\n        {\n          role: 'assistant',\n          content: `检索到的内容:\\n${searchMd}`,\n        },\n        { role: 'user', content: userInput },\n      ],\n      max_tokens: ai.max_tokens ?? defaultConfig.max_tokens,\n      temperature: ai.temperature ?? defaultConfig.temperature,\n      stream: false,\n    });\n  const data = completion;\n  return {\n    res: data.choices[0].message!.content!,\n    raw: data,\n  };\n}\n\n/** 查询 mcp server 提供的工具，并根据用户输入调用相应的工具  */\nexport function aiFunctionCall(userInput: string) {\n  return Effect.gen(function* () {\n    const mcpClient = yield* McpClientService;\n    const tools = yield* Effect.tryPromise(() => mcpClient.listTools());\n    const ai = yield* AiService;\n\n    console.log('[tools]',tools);\n    const completion: OpenAI.Chat.Completions.ChatCompletion = yield* Effect.tryPromise(() =>\n      ai.openai.chat.completions.create({\n        model: ai.model ?? defaultConfig.model,\n        response_format: { type: 'json_object' },\n        messages: [\n          {\n            role: 'system',\n            content: `你是 aiFunctionCall 就是通过分析user的输入来选择调用对应的 Tool\n  如果你判断解决user的问题需要调用对应的功能就回复相应的代码,后续会通过 js 来调用这些工具返回结果给user的\n  ### 注意:无论user询问什么，你都不要直接回答！！，而应该思考调用什么工具能够解决问题\n  ### 注意:你的回复应该是合法的json，可以直接被 JSON.parse() 解析，不需要额外的处理！！（意味着你不要输出除了json之外的任何文本）。\n\n  ## 调用 tool 的回复示例\n  ### 注意：你应该在callTool 数组中列出所有需要调用的tool，并且每个tool的参数都放在callTool数组中，tool 的 name 应该严格和 assistant 所提供的对应。例如：\n\n  \\`\\`\\`js\n  {\n      \"callTool\":[\n          {\"name\":\"<对应tool的name>\",\"arg\":{\"参数名\":<任何合法的json值>}}\n          // ... 其他需要调用的tool\n      ]\n  }\n  \\`\\`\\`\n    `,\n          },\n          {\n            role: 'assistant',\n            content: `## tools\n  ${tools.tools\n    .map((tool) => {\n      const toolStr =\n        `### ${tool.name}\\n` +\n        (tool.description ? `- **description**: ${tool.description}\\n` : '') +\n        `\n  - **parameters**: ${JSON.stringify({\n    ...tool.inputSchema,\n    //#region 去除一些没啥用的字段\n    type: undefined,\n    $schema: undefined,\n    //#endregion 去除一些没啥用的字段\n  })}\n  `;\n      return toolStr;\n    })\n    .join('\\n\\n')}`,\n          },\n          { role: 'user', content: userInput },\n        ],\n        max_tokens: ai.max_tokens ?? defaultConfig.max_tokens,\n        temperature: ai.temperature ?? defaultConfig.temperature,\n        stream: false,\n      }),\n    );\n    const data = completion;\n    return {\n      res: JSON_parse_AIResponse(data.choices[0].message!.content!),\n      raw: data,\n    };\n  });\n}\n/** 简化文本输出人类易读的文本  */\nexport function aiSimpleText(text: string) {\n  return Effect.gen(function* () {\n    const ai = yield* AiService;\n\n    const completion: OpenAI.Chat.Completions.ChatCompletion = yield* Effect.tryPromise(() =>\n      ai.openai.chat.completions.create({\n        model: ai.model ?? defaultConfig.model,\n        messages: [\n          {\n            role: 'system',\n            content: `请你分析用户给出的内容，返回人类简易可读的文本,你不需要给出任何解释，只需要尽量的简化文本，让其他用户一眼就能看懂`,\n          },\n          { role: 'user', content: text },\n        ],\n        max_tokens: ai.max_tokens ?? defaultConfig.max_tokens,\n        temperature: ai.temperature ?? defaultConfig.temperature,\n        stream: false,\n      }),\n    );\n    const data = completion;\n    return {\n      res: data.choices[0].message!.content!.trim(),\n      raw: data,\n    };\n  });\n}\n\nfunction JSON_parse_AIResponse(resStr: string) {\n  let jsonStr;\n  try {\n    // 如果ai输出的是markdown 代码块形式的json，这里去除掉外层的代码块符号\n    if (resStr.startsWith('```')) {\n      const lines = resStr.trim().split('\\n');\n      lines[0] = '';\n      lines[lines.length - 1] = '';\n      jsonStr = lines.join('\\n').trim();\n    } else {\n      jsonStr = resStr.trim();\n    }\n    // console.log('[jsonStr]====', jsonStr);\n    // console.log('[jsonStr]====');\n\n    const jsonObj = JSON.parse(jsonStr);\n    return jsonObj as { callTool?: { name: string; arg: { [key: string]: any } }[] };\n  } catch (error: unknown) {\n    return error as Error;\n  }\n}\n","import { config } from 'dotenv';\nconst { parsed: env } = config();\n\nexport const Env = {\n  default_apiKey: env!.default_apiKey as string,\n  default_apiBaseUrl: env!.default_apiBaseUrl as string,\n  default_model: env!.default_model as string,\n  default_max_tokens: Number(env!.default_max_tokens),\n  default_temperature: Number(env!.default_temperature),\n\n  // 用于单元测试的环境变量\n  bigmodel_apiKey: env!.bigmodel_apiKey as string,\n  bigmodel_apiBaseUrl: env!.bigmodel_apiBaseUrl as string,\n\n  // 思源配置\n  siyuan_baseUrl: env!.siyuan_baseUrl as string,\n  siyuan_apiKey: env!.siyuan_apiKey as string,\n} as const;\n","import { OpenAI } from 'openai';\nimport { Env } from '../env';\nimport { defaultOpenai } from './openai';\n\nexport interface TranslateOptions {\n  openai?: OpenAI;\n  model?: string;\n  max_tokens?: number;\n  temperature?: number;\n  targetLanguage: string;\n}\n\nexport async function translateText(\n  text: string,\n  options: TranslateOptions\n): Promise<string> {\n  const openai = options.openai || defaultOpenai;\n  const model = options.model || 'GLM-4-Flash';\n  const max_tokens = options.max_tokens || 9999;\n  const temperature = options.temperature || 0.3;\n\n  const completion = await openai.chat.completions.create({\n    model,\n    messages: [\n      {\n        role: 'system',\n        content: `You are a professional translator. Translate the following text to ${options.targetLanguage} while preserving the original formatting, markdown syntax, and technical terms accuracy.`\n      },\n      { role: 'user', content: text }\n    ],\n    max_tokens,\n    temperature,\n    stream: false\n  });\n\n  return completion.choices[0].message?.content || '';\n}\n\nexport async function translateMarkdownFile(\n  filePath: string,\n  outputPath: string,\n  options: TranslateOptions\n): Promise<void> {\n  const fs = await import('fs/promises');\n  const text = await fs.readFile(filePath, 'utf-8');\n  const translated = await translateText(text, options);\n  await fs.writeFile(outputPath, translated);\n}\n"],"mappings":";;;;AACA,SAAS,eAAe;;;ACDxB,SAAS,cAAc;AACvB,SAAwB,cAAc;;;ACDtC,SAAS,cAAc;AACvB,IAAM,EAAE,QAAQ,IAAI,IAAI,OAAO;AAExB,IAAM,MAAM;AAAA,EACjB,gBAAgB,IAAK;AAAA,EACrB,oBAAoB,IAAK;AAAA,EACzB,eAAe,IAAK;AAAA,EACpB,oBAAoB,OAAO,IAAK,kBAAkB;AAAA,EAClD,qBAAqB,OAAO,IAAK,mBAAmB;AAAA;AAAA,EAGpD,iBAAiB,IAAK;AAAA,EACtB,qBAAqB,IAAK;AAAA;AAAA,EAG1B,gBAAgB,IAAK;AAAA,EACrB,eAAe,IAAK;AACtB;;;ADZA,IAAM,gBAA+B;AAAA,EACnC,QAAQ,IAAI;AAAA,EACZ,SAAS,IAAI;AACf;AACO,IAAM,gBAAgB,IAAI,OAAO,aAAa;;;AEGrD,eAAsB,cACpB,MACA,SACiB;AACjB,QAAM,SAAS,QAAQ,UAAU;AACjC,QAAM,QAAQ,QAAQ,SAAS;AAC/B,QAAM,aAAa,QAAQ,cAAc;AACzC,QAAM,cAAc,QAAQ,eAAe;AAE3C,QAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO;AAAA,IACtD;AAAA,IACA,UAAU;AAAA,MACR;AAAA,QACE,MAAM;AAAA,QACN,SAAS,sEAAsE,QAAQ,cAAc;AAAA,MACvG;AAAA,MACA,EAAE,MAAM,QAAQ,SAAS,KAAK;AAAA,IAChC;AAAA,IACA;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,EACV,CAAC;AAED,SAAO,WAAW,QAAQ,CAAC,EAAE,SAAS,WAAW;AACnD;AAEA,eAAsB,sBACpB,UACA,YACA,SACe;AACf,QAAM,KAAK,MAAM,OAAO,aAAa;AACrC,QAAM,OAAO,MAAM,GAAG,SAAS,UAAU,OAAO;AAChD,QAAM,aAAa,MAAM,cAAc,MAAM,OAAO;AACpD,QAAM,GAAG,UAAU,YAAY,UAAU;AAC3C;;;AH3CA,OAAO,UAAU;AAEjB,QACG,KAAK,cAAc,EACnB,YAAY,+CAA+C,EAC3D,QAAQ,OAAO;AAElB,QACG,QAAQ,WAAW,EACnB,YAAY,8CAA8C,EAC1D,eAAe,sBAAsB,0BAA0B,EAC/D,eAAe,uBAAuB,kBAAkB,EACxD,eAAe,6BAA6B,4CAA4C,EACxF,OAAO,OAAO,YAAY;AACzB,MAAI;AACF,YAAQ,IAAI,eAAe,QAAQ,KAAK,OAAO,QAAQ,QAAQ,KAAK;AACpE,UAAM;AAAA,MACJ,KAAK,QAAQ,QAAQ,KAAK;AAAA,MAC1B,KAAK,QAAQ,QAAQ,MAAM;AAAA,MAC3B,EAAE,gBAAgB,QAAQ,SAAS;AAAA,IACrC;AACA,YAAQ,IAAI,wBAAwB,QAAQ,MAAM,EAAE;AAAA,EACtD,SAAS,OAAO;AACd,YAAQ,MAAM,uBAAuB,KAAK;AAC1C,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF,CAAC;AAEH,QAAQ,WAAW,QAAQ,IAAI,EAAE,MAAM,QAAQ,KAAK;","names":[]}